{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "958897e1-d8ec-456d-b3ca-e5e69e18fe8c",
   "metadata": {},
   "source": [
    "# Task 4 — General Health Query Chatbot (Prompt Engineering Based)\n",
    "#\n",
    "## Objective:\n",
    "## - Build a simple chatbot that answers general health-related questions using an LLM.\n",
    "## - Use prompt engineering to make responses friendly and clear.\n",
    "## - Add safety filters to avoid giving harmful medical advice.\n",
    "##\n",
    "## Notes:\n",
    "## - This notebook supports OpenAI's Chat API (gpt-3.5) if you set OPENAI_API_KEY as an env var.\n",
    "## - An optional fallback path using Hugging Face Inference API is provided (requires HF token).\n",
    "## - Always include disclaimers and refuse to provide diagnosis/medical prescriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadffd14-be1d-4ff2-809c-432d72306864",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Basic imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from getpass import getpass\n",
    "\n",
    "# Install openai if not available (uncomment in notebook)\n",
    "# !pip install openai\n",
    "\n",
    "# %%\n",
    "# Helper: Safety filter (simple rule-based)\n",
    "# If a user asks for diagnosis, dosing, or emergency instructions, the assistant will refuse and direct to a professional.\n",
    "DANGEROUS_PATTERNS = [\n",
    "    r'\\bdiagnos(e|is|ing)\\b',\n",
    "    r'\\bprescrib(e|ing|ed)\\b',\n",
    "    r'\\bwhat (dose|dosage)\\b',\n",
    "    r'\\bhow much (mg|ml|tablets?)\\b',\n",
    "    r'\\bemergency\\b',\n",
    "    r'\\bpoison\\b',\n",
    "    r'\\bself[- ]harm\\b',\n",
    "    r'\\bkill myself\\b',\n",
    "    r'\\bsuicid(e|al)\\b'\n",
    "]\n",
    "\n",
    "def is_dangerous_query(text):\n",
    "    t = text.lower()\n",
    "    for p in DANGEROUS_PATTERNS:\n",
    "        if re.search(p, t):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# %%\n",
    "# OpenAI Chat function (if you have an API key)\n",
    "def chat_with_openai(messages, model=\"gpt-3.5-turbo\", max_tokens=400, temperature=0.2):\n",
    "    try:\n",
    "        import openai\n",
    "    except Exception as e:\n",
    "        raise RuntimeError(\"openai package not installed. pip install openai\") from e\n",
    "\n",
    "    api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"OpenAI API key not found. Set OPENAI_API_KEY env var.\")\n",
    "    openai.api_key = api_key\n",
    "\n",
    "    resp = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        max_tokens=max_tokens,\n",
    "        temperature=temperature\n",
    "    )\n",
    "    return resp['choices'][0]['message']['content'].strip()\n",
    "\n",
    "# %%\n",
    "# Hugging Face Inference fallback (optional) - uses text-generation via inference API\n",
    "def chat_with_hf(prompt, hf_token=None, model=\"gpt2\"):\n",
    "    import requests\n",
    "    if hf_token is None:\n",
    "        hf_token = os.getenv(\"HF_API_TOKEN\")\n",
    "    if not hf_token:\n",
    "        raise RuntimeError(\"Hugging Face API token not found. Set HF_API_TOKEN env var.\")\n",
    "    headers = {\"Authorization\": f\"Bearer {hf_token}\"}\n",
    "    api_url = f\"https://api-inference.huggingface.co/models/{model}\"\n",
    "    payload = {\"inputs\": prompt, \"options\": {\"wait_for_model\": True}}\n",
    "    resp = requests.post(api_url, headers=headers, json=payload, timeout=120)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError(f\"Hugging Face inference failed: {resp.status_code} {resp.text}\")\n",
    "    output = resp.json()\n",
    "    # output can be list of generations\n",
    "    try:\n",
    "        return output[0]['generated_text']\n",
    "    except Exception:\n",
    "        return str(output)\n",
    "\n",
    "# %%\n",
    "# Prompt engineering: system + few-shot examples\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a helpful and friendly medical information assistant. Provide general, non-diagnostic health information in clear, empathetic language.\n",
    "Always include a short disclaimer: \"I am not a doctor. For medical diagnosis or treatment, please consult a healthcare professional.\"\n",
    "If a query requests diagnosis, prescription, dosing, or emergency/urgent actions, refuse politely and direct the user to seek professional help or emergency services.\n",
    "Prioritize safety and do not provide specific dosing or prescription instructions.\n",
    "\"\"\"\n",
    "\n",
    "# Short few-shot examples to guide style\n",
    "EXAMPLES = [\n",
    "    {\"role\":\"user\", \"content\":\"What causes a sore throat?\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"A sore throat can be caused by viral infections (like the common cold), bacterial infections (such as strep throat), allergies, dry air, or irritation from smoke. Rest, fluids, and saltwater gargles can help. If you have a high fever, difficulty breathing, or severe pain, see a healthcare professional.\"},\n",
    "    {\"role\":\"user\", \"content\":\"Is paracetamol safe for children?\"},\n",
    "    {\"role\":\"assistant\", \"content\":\"Paracetamol (acetaminophen) is commonly used for fever and pain in children, but the dose depends on the child's weight and age. Always follow product dosing instructions or ask a pediatrician. If you suspect an overdose or the child is unwell, seek immediate medical attention. I am not a doctor.\"}\n",
    "]\n",
    "\n",
    "# %%\n",
    "# Interactive loop (works in Jupyter)\n",
    "def run_chatbot():\n",
    "    print(\"General Health Chatbot. Type 'exit' to quit.\")\n",
    "    # Build base messages\n",
    "    base_messages = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT}]\n",
    "    # Add examples\n",
    "    for ex in EXAMPLES:\n",
    "        base_messages.append(ex)\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() in (\"exit\", \"quit\"):\n",
    "            print(\"Goodbye — remember this is only general information.\")\n",
    "            break\n",
    "\n",
    "        # Safety filter\n",
    "        if is_dangerous_query(user_input):\n",
    "            print(\"Assistant: I'm sorry, I can't provide medical diagnoses, prescriptions, or emergency instructions. Please contact a healthcare professional or emergency services.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare messages\n",
    "        msgs = base_messages + [{\"role\":\"user\", \"content\": user_input}]\n",
    "        # Try OpenAI first\n",
    "        try:\n",
    "            answer = chat_with_openai(msgs)\n",
    "        except Exception as e:\n",
    "            print(f\"[OpenAI unavailable or error: {e}] Trying Hugging Face fallback if configured...\")\n",
    "            try:\n",
    "                prompt = SYSTEM_PROMPT + \"\\n\\nUser: \" + user_input + \"\\nAssistant:\"\n",
    "                answer = chat_with_hf(prompt)\n",
    "            except Exception as e2:\n",
    "                print(\"No LLM backend available:\", e2)\n",
    "                continue\n",
    "\n",
    "        # Add final safety reminder (will also be in system prompt)\n",
    "        if \"I am not a doctor\" not in answer:\n",
    "            answer = answer.strip() + \"\\n\\nDisclaimer: I am not a doctor. For a medical diagnosis or treatment plan, consult a qualified healthcare professional.\"\n",
    "\n",
    "        print(\"\\nAssistant:\", answer)\n",
    "\n",
    "# %%\n",
    "# Run the interactive chatbot (uncomment to run in a notebook)\n",
    "# run_chatbot()\n",
    "\n",
    "# %%\n",
    "# Example usage programmatically\n",
    "def answer_query(query, backend=\"openai\"):\n",
    "    if is_dangerous_query(query):\n",
    "        return \"I'm sorry, I can't help with diagnosis, prescriptions, dosing, or emergency instructions. Please contact a healthcare professional or emergency services.\"\n",
    "\n",
    "    msgs = [{\"role\":\"system\",\"content\":SYSTEM_PROMPT}]\n",
    "    for ex in EXAMPLES:\n",
    "        msgs.append(ex)\n",
    "    msgs.append({\"role\":\"user\",\"content\":query})\n",
    "\n",
    "    if backend==\"openai\":\n",
    "        return chat_with_openai(msgs)\n",
    "    else:\n",
    "        prompt = SYSTEM_PROMPT + \"\\n\\nUser: \" + query + \"\\nAssistant:\"\n",
    "        return chat_with_hf(prompt)\n",
    "\n",
    "# %%\n",
    "# Quick test (replace with actual API keys in env vars)\n",
    "if __name__ == \"__main__\" and sys.stdin.isatty():\n",
    "    print(\"Run interactive chatbot by calling run_chatbot() or using answer_query().\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb129cd5-56fb-4c1c-b2a3-4c4773f8f99a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
